{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JejNB7rGIfCU"
      },
      "source": [
        "#1. Nettoyage des données\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RFDD_Yz8HqxZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Check if the file exists\n",
        "file_path = \"/content/hotels.xlsx\"\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"Error: File '{file_path}' not found.\")\n",
        "    df_hotels = None\n",
        "else:\n",
        "    try:\n",
        "        xls = pd.ExcelFile(file_path)\n",
        "        df_hotels = xls.parse('Hotels')\n",
        "        df_comments = xls.parse('Commentaires')\n",
        "        df_questions = xls.parse('QuestionReponse')\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the Excel file: {e}\")\n",
        "        df_hotels = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh9S-A-hIIih",
        "outputId": "cc12551e-83d3-4f16-b701-0f8bb2460b10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lieu                          object\n",
            "Nom HOTEL                     object\n",
            "adresse                       object\n",
            "Etoile                        object\n",
            "Prix                           int64\n",
            "Rate nominal                  object\n",
            "Rate ordinal                  object\n",
            "Expériences vécues            object\n",
            "points fort                   object\n",
            "Lieux à proximité             object\n",
            "Restaurants et cafés          object\n",
            "Plages à proximité            object\n",
            "Transports en commun          object\n",
            "Aéroports les plus proches    object\n",
            "a savoir                      object\n",
            "Enfants et lits               object\n",
            "Arrive                        object\n",
            "depart                        object\n",
            "restriction d'age             object\n",
            "Animaux domestiques           object\n",
            "dtype: object\n",
            "\n",
            "Missing Values:\n",
            " Lieu                          0\n",
            "Nom HOTEL                     0\n",
            "adresse                       0\n",
            "Etoile                        0\n",
            "Prix                          0\n",
            "Rate nominal                  0\n",
            "Rate ordinal                  0\n",
            "Expériences vécues            0\n",
            "points fort                   0\n",
            "Lieux à proximité             0\n",
            "Restaurants et cafés          0\n",
            "Plages à proximité            0\n",
            "Transports en commun          0\n",
            "Aéroports les plus proches    0\n",
            "a savoir                      0\n",
            "Enfants et lits               0\n",
            "Arrive                        0\n",
            "depart                        0\n",
            "restriction d'age             0\n",
            "Animaux domestiques           0\n",
            "dtype: int64\n",
            "\n",
            "Missing Value Percentage:\n",
            " Lieu                          0.0\n",
            "Nom HOTEL                     0.0\n",
            "adresse                       0.0\n",
            "Etoile                        0.0\n",
            "Prix                          0.0\n",
            "Rate nominal                  0.0\n",
            "Rate ordinal                  0.0\n",
            "Expériences vécues            0.0\n",
            "points fort                   0.0\n",
            "Lieux à proximité             0.0\n",
            "Restaurants et cafés          0.0\n",
            "Plages à proximité            0.0\n",
            "Transports en commun          0.0\n",
            "Aéroports les plus proches    0.0\n",
            "a savoir                      0.0\n",
            "Enfants et lits               0.0\n",
            "Arrive                        0.0\n",
            "depart                        0.0\n",
            "restriction d'age             0.0\n",
            "Animaux domestiques           0.0\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Check data types\n",
        "print(df_hotels.dtypes)\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df_hotels.isnull().sum()\n",
        "missing_percentage = (missing_values / len(df_hotels)) * 100\n",
        "print(\"\\nMissing Values:\\n\", missing_values)\n",
        "print(\"\\nMissing Value Percentage:\\n\", missing_percentage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrsyyE7i05gR",
        "outputId": "f82371b0-402a-4f31-9b63-4ad46810da0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nom hotel           object\n",
            "Note                object\n",
            "Titre               object\n",
            "Commentaire         object\n",
            "Date commentaire    object\n",
            "dtype: object\n",
            "\n",
            "Missing Values:\n",
            " nom hotel            0\n",
            "Note                17\n",
            "Titre                0\n",
            "Commentaire          0\n",
            "Date commentaire    17\n",
            "dtype: int64\n",
            "\n",
            "Missing Value Percentage:\n",
            " nom hotel           0.000000\n",
            "Note                0.458468\n",
            "Titre               0.000000\n",
            "Commentaire         0.000000\n",
            "Date commentaire    0.458468\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Check data types\n",
        "print(df_comments.dtypes)\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df_comments.isnull().sum()\n",
        "missing_percentage = (missing_values / len(df_comments)) * 100\n",
        "print(\"\\nMissing Values:\\n\", missing_values)\n",
        "print(\"\\nMissing Value Percentage:\\n\", missing_percentage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcEVRYdA056_",
        "outputId": "43590267-5b2f-49d7-b988-81e30fba9028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nom hotel      object\n",
            "question       object\n",
            "answer_text    object\n",
            "dtype: object\n",
            "\n",
            "Missing Values:\n",
            " nom hotel      0\n",
            "question       0\n",
            "answer_text    0\n",
            "dtype: int64\n",
            "\n",
            "Missing Value Percentage:\n",
            " nom hotel      0.0\n",
            "question       0.0\n",
            "answer_text    0.0\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Check data types\n",
        "print(df_questions.dtypes)\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df_questions.isnull().sum()\n",
        "missing_percentage = (missing_values / len(df_questions)) * 100\n",
        "print(\"\\nMissing Values:\\n\", missing_values)\n",
        "print(\"\\nMissing Value Percentage:\\n\", missing_percentage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CUfJbYMoIKKl"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "# Function to clean text (remove special characters, accents)\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[éèêë]', 'e', text)\n",
        "        text = re.sub(r'[àâä]', 'a', text)\n",
        "        text = re.sub(r'[îï]', 'i', text)\n",
        "        text = re.sub(r'[ôö]', 'o', text)\n",
        "        text = re.sub(r'[ùûü]', 'u', text)\n",
        "        text = re.sub(r'[^a-zA-Z0-9\\s,]', '', text)  # Remove special characters\n",
        "    return text\n",
        "\n",
        "# Cleaning Hotels sheet\n",
        "df_hotels = df_hotels.rename(columns=lambda x: clean_text(x))  # Normalize column names\n",
        "df_hotels['nom hotel'] = df_hotels['nom hotel'].apply(clean_text)\n",
        "df_hotels['etoile'] = pd.to_numeric(df_hotels['etoile'], errors='coerce')  # Convert stars to numeric\n",
        "df_hotels['prix'] = pd.to_numeric(df_hotels['prix'], errors='coerce')  # Convert price to numeric\n",
        "\n",
        "# Cleaning Commentaires sheet\n",
        "df_comments = df_comments.rename(columns=lambda x: clean_text(x))\n",
        "df_comments['nom hotel'] = df_comments['nom hotel'].apply(clean_text)\n",
        "df_comments['note'] = df_comments['note'].astype(str).str.replace(',', '.').astype(float)  # Convert ratings to float\n",
        "\n",
        "# Cleaning QuestionReponse sheet\n",
        "df_questions = df_questions.rename(columns=lambda x: clean_text(x))\n",
        "df_questions['nom hotel'] = df_questions['nom hotel'].apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalize the locations ' jandouba and jendouba , delete the duplicated hotels"
      ],
      "metadata": {
        "id": "lOJQGZcyneya"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TGu6bkGJ8E2"
      },
      "source": [
        "#3. Préparation des données pour le ChatBot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8huzRJI1nXn"
      },
      "source": [
        "##3.1 Convertion vers Json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNmqqQjd1qT5",
        "outputId": "3a2ebb8c-4a46-43c5-e671-e9181c774ed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON file saved at: hotels_data.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "# Assign unique hotel IDs\n",
        "df_hotels['hotel_id'] = np.arange(1, len(df_hotels) + 1)\n",
        "\n",
        "# Merge comments and questions with hotel data\n",
        "hotels_json = []\n",
        "for _, hotel in df_hotels.iterrows():\n",
        "    hotel_id = hotel['hotel_id']\n",
        "    hotel_name = hotel['nom hotel']\n",
        "\n",
        "    # Extract comments for the current hotel\n",
        "    comments = df_comments[df_comments['nom hotel'] == hotel_name][['titre', 'commentaire', 'note', 'date commentaire']].to_dict(orient='records')\n",
        "\n",
        "    # Extract questions & answers for the current hotel\n",
        "    questions = df_questions[df_questions['nom hotel'] == hotel_name][['question', 'answertext']].to_dict(orient='records')\n",
        "\n",
        "    # Construct hotel JSON object\n",
        "    hotel_data = {\n",
        "        \"hotel_id\": int(hotel_id),\n",
        "        \"name\": hotel['nom hotel'],\n",
        "        \"location\": hotel['lieu'],\n",
        "        \"address\": hotel['adresse'],\n",
        "        \"stars\": hotel['etoile'],\n",
        "        \"price\": hotel['prix'],\n",
        "        \"rating\": hotel['rate nominal'],\n",
        "        \"features\": hotel['points fort'],\n",
        "        \"nearby_places\": hotel['lieux a proximite'],\n",
        "        \"nearby_beaches\": hotel['plages a proximite'],\n",
        "        \"transport\": hotel['transports en commun'],\n",
        "        \"airports\": hotel['aeroports les plus proches'],\n",
        "        \"policies\": {\n",
        "            \"checkin\": hotel['arrive'],\n",
        "            \"checkout\": hotel['depart'],\n",
        "            \"age_restriction\": hotel['restriction dage'],\n",
        "            \"pets\": hotel['animaux domestiques'],\n",
        "            \"children_beds\": hotel['enfants et lits']\n",
        "        },\n",
        "        \"additional_info\": hotel['a savoir'],\n",
        "        \"comments\": comments,\n",
        "        \"faq\": questions\n",
        "    }\n",
        "\n",
        "    hotels_json.append(hotel_data)\n",
        "\n",
        "# Save to JSON file\n",
        "json_output_path = \"hotels_data.json\"\n",
        "with open(json_output_path, \"w\", encoding=\"utf-8\") as json_file:\n",
        "    json.dump(hotels_json, json_file, indent=4, ensure_ascii=False)\n",
        "\n",
        "print(f\"JSON file saved at: {json_output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# un peu de temps pour qu'il enregistre le fichier json\n",
        "import time\n",
        "time.sleep(5)\n"
      ],
      "metadata": {
        "id": "E5ZG0qwrQNdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Choix des informations"
      ],
      "metadata": {
        "id": "JUNw-c-eK-F_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "j'ai voulu travaillez avec les commentaires mais les chunks sont trés grandes et prend beaucoup de temps ( plus que 3 heures )"
      ],
      "metadata": {
        "id": "B5SJduFMLIbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_hotels = pd.read_json('hotels_data.json')\n",
        "\n",
        "# nettoyage des espaces dans les caractéristiques et les plages\n",
        "if df_hotels is not None and 'nearby_beaches' in df_hotels.columns:\n",
        "  for index, row in df_hotels.iterrows():\n",
        "    if isinstance(row['nearby_beaches'], str):\n",
        "      df_hotels.at[index, 'nearby_beaches'] = row['nearby_beaches'].replace('\\\\n', ' ')\n",
        "  print(df_hotels[\"nearby_beaches\"])\n",
        "else:\n",
        "  print(\"DataFrame or 'nearby_beaches' column not found.\")\n",
        "df_hotels[\"nearby_beaches\"]\n",
        "\n",
        "def clean_list_field(field_value):\n",
        "    try:\n",
        "        items = ast.literal_eval(field_value)\n",
        "        if isinstance(items, list):\n",
        "            cleaned = list(dict.fromkeys([item.replace('\\\\n', ' ').strip().lower() for item in items if isinstance(item, str)]))\n",
        "            return ', '.join(cleaned)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return 'non renseigné'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go5qy3FLLHr0",
        "outputId": "baa035d2-520d-4c32-8ff6-c1d6168cde75"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      ['Plage de Boujaafar 500 m', 'Plage de Bhar Ez...\n",
            "1      ['Plage de Bhar Ezzebla 750 m', 'Plage de Bouj...\n",
            "2      ['Las Vegas Beach 850 m', 'Plage de Boujaafar ...\n",
            "3      ['Plage de Boujaafar 600 m', 'Plage de Bhar Ez...\n",
            "4      ['Plage de Boujaafar 700 m', 'Plage de Bhar Ez...\n",
            "                             ...                        \n",
            "392    [\"Plages d'Hammamet 50 m\", 'Plage du Sentido A...\n",
            "393    [\"Plages d'Hammamet 10 m\", 'Plage de Yasmine H...\n",
            "394    ['Plage de Mrezga 450 m', 'Plage de Hammamet 1...\n",
            "395    [\"Plages d'Hammamet 650 m\", 'Plage de Yasmine ...\n",
            "396    ['Plage de Yasmine Hammamet 550 m', \"Plages d'...\n",
            "Name: nearby_beaches, Length: 397, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# générer une colonne qui combine tous les informations d'un seul hotel\n",
        "def generate_text(row):\n",
        "    name = row.get('name', 'nom inconnu')\n",
        "    location = row.get('location', 'localisation inconnue')\n",
        "    price = row.get('price', 'prix non renseigné')\n",
        "    rating = row.get('rating', 'note non disponible')\n",
        "\n",
        "    features = clean_list_field(row.get('features', ''))\n",
        "    beaches = clean_list_field(row.get('nearby_beaches', ''))\n",
        "\n",
        "    return (\n",
        "        f\"Nom de l'hôtel : {name}.\\n\"\n",
        "        f\"Localisation : {location}.\\n\"\n",
        "        f\"Prix : {price} TND par nuit.\\n\"\n",
        "        f\"Note : {rating}.\\n\"\n",
        "        f\"Caractéristiques : {features}.\\n\"\n",
        "        f\"Plages à proximité : {beaches}.\\n\"\n",
        "    )\n",
        "\n",
        "df_hotels['text'] = df_hotels.apply(generate_text, axis=1)"
      ],
      "metadata": {
        "id": "Soi9cS6NLfZQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding"
      ],
      "metadata": {
        "id": "4Tpk5tFLLiza"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr7e2o4RTPV1",
        "outputId": "50334ca8-09b7-4194-abfe-138e39eff426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.9/18.9 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.7/437.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Installation des bibliothèques nécessaires\n",
        "!pip install langchain langchain-community pypdf chromadb -q\n",
        "!pip install langchain_groq -q\n",
        "!pip install -U langchain-huggingface -q\n",
        "!pip install -U langchain-chroma -q\n",
        "!pip install gradio -q\n",
        "\n",
        "!pip install language_tool_python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKK0VENVTIDS"
      },
      "outputs": [],
      "source": [
        "# Importations\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import Document\n",
        "\n",
        "import os\n",
        "import gradio as gr\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "on a choisi le e5-large-v2 au lieu de all MiniLM-v6 car il gére plus de token ( 1024 aux lieu de 384) et plus adapté pour les descriptions détaillées des hotels mais il prend beaucoup de temps"
      ],
      "metadata": {
        "id": "WphC6fKjNe7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Hugging Face embeddings model\n",
        "embedding_function = HuggingFaceEmbeddings(model_name=\"intfloat/e5-large-v2\")\n",
        "\n",
        "# Generate embeddings for the 'text' column\n",
        "hotel_embeddings = embedding_function.embed_documents(df_hotels['text'].tolist())\n",
        "\n",
        "# Print the shape of the embeddings\n",
        "print(f\"Shape of the embeddings: {len(hotel_embeddings)}, {len(hotel_embeddings[0])}\")"
      ],
      "metadata": {
        "id": "y5OeZRNENcGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "le choix des chunk est :\n",
        "\n",
        "\n",
        "*   size 300 et overlap 50 : trop petit et génére des erreurs\n",
        "*   size 1200 et overlap 350 : prend plus que 3 heures pour executer\n",
        "*   size 1000 et overlap 300 : parfait pour les hotels sans les commentaires"
      ],
      "metadata": {
        "id": "wDfJAP8OObiE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09yXlzpaKBtA"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.schema import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Split the text into chunks\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=300)\n",
        "documents = [Document(page_content=t) for t in df_hotels['text'].tolist()]\n",
        "split_docs = splitter.split_documents(documents)\n",
        "\n",
        "# Persisted vectorstore\n",
        "persist_directory = \"chroma_db\"\n",
        "\n",
        "\n",
        "if os.path.exists(persist_directory):\n",
        "    print(\"Chargement de la base Chroma existante...\")\n",
        "    vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embedding_function)\n",
        "else:\n",
        "    print(\"Création d'une nouvelle base Chroma...\")\n",
        "    vectorstore = Chroma.from_documents(\n",
        "    documents=split_docs,\n",
        "    embedding=embedding_function,\n",
        "    persist_directory=persist_directory,\n",
        "    collection_name=\"hotels\",\n",
        "    )\n",
        "vectorstore.persist()\n",
        "\n",
        "# Now reload the persisted vectorstore\n",
        "vectorstore = Chroma(\n",
        "    embedding_function=embedding_function,\n",
        "    persist_directory=persist_directory,\n",
        "    collection_name=\"hotels\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOb2U5e_XPIm"
      },
      "outputs": [],
      "source": [
        "llm = ChatGroq(model=\"llama-3.3-70b-versatile\", api_key=\"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\")\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "   template=(\n",
        "        \"tu es un assistant expert en tourisme et hôtels en particulier en tunisie\"\n",
        "        #resumer moi l'hotel par les avis\n",
        "        \"Répondez avec des informations précises et pertinentes en vous basant uniquement sur le contexte fourni.\\n\\n\"\n",
        "        \"Contexte: {context}\\n\"\n",
        "        \"Question du client: {question}\\n\\n\"\n",
        "        \"Réponse détaillée:\"\n",
        "   ),\n",
        "   input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "   llm=llm,\n",
        "   chain_type=\"stuff\",\n",
        "   retriever=vectorstore.as_retriever(),\n",
        "   return_source_documents=True,\n",
        "   chain_type_kwargs={\"prompt\": prompt_template}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(query):\n",
        "    result = qa_chain({\"query\": query})\n",
        "    return result['result']\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=chatbot,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Hotel RAG Chatbot\",\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "CVl55zULPcvO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}